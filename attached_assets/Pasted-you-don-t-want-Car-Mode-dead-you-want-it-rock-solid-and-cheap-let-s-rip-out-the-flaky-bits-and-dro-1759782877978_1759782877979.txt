you don‚Äôt want Car Mode dead; you want it rock-solid and cheap. let‚Äôs rip out the flaky bits and drop in a Car Mode V2 that:

works hands-free (or push-to-talk)

doesn‚Äôt spam APIs (built-in VAD + batching)

routes recognized commands straight to your /calendar-multi/command endpoint

is additive (new module/route + a new UI panel), no touch to your other pipelines

below is a complete, drop-in package. paste it in, set one env var, and you‚Äôve got a reliable loop.

what this gives you

client (React): mic capture ‚Üí voice activity detection (VAD) ‚Üí chunked uploads; optional push-to-talk; on-device TTS for responses (free).

server (Express TS): /car-v2/stt accepts short audio chunks, calls Whisper (OpenAI) safely with backoff + circuit breaker, returns final transcript. Then the client calls /calendar-multi/command automatically when it hears an intent (‚Äúcreate‚Ä¶‚Äù, ‚Äúfind‚Ä¶‚Äù).

cost guardrails: session caps, per-minute caps, exponential backoff, auto-mute on repeated errors.

env you need: OPENAI_API_KEY (for Whisper). that‚Äôs it. (no GCP, no extra clouds.)

1) server ‚Äî additive route

src/modules/carModeV2/index.ts

import express from "express";
import multer from "multer";
import fs from "fs";
import path from "path";
import crypto from "crypto";

const router = express.Router();
const upload = multer({ storage: multer.memoryStorage(), limits: { fileSize: 8 * 1024 * 1024 } });

const OPENAI_API_KEY = process.env.OPENAI_API_KEY || "";
if (!OPENAI_API_KEY) console.warn("[CARV2] OPENAI_API_KEY missing ‚Äî STT will 500.");

// ====== tiny circuit breaker ======
let failCount = 0;
let openedUntil = 0;
const OPEN_THRESHOLD = 4;           // 4 consecutive fails
const OPEN_MS = 60_000;             // 1 min pause

function breakerOpen() {
  if (Date.now() < openedUntil) return true;
  return false;
}
function breakerTrip() {
  failCount++;
  if (failCount >= OPEN_THRESHOLD) {
    openedUntil = Date.now() + OPEN_MS;
    failCount = 0;
    console.error("[CARV2] breaker OPEN for 60s");
  }
}
function breakerSuccess() {
  failCount = 0;
}

// ====== budget guard ======
const MAX_MINUTES_PER_SESSION = Number(process.env.CARV2_MAX_MIN || 5); // hard cap
const MAX_REQ_PER_MIN = Number(process.env.CARV2_MAX_REQ_PM || 8);
let tick = Math.floor(Date.now() / 60_000);
let reqThisMin = 0;

function rateOK() {
  const nowTick = Math.floor(Date.now() / 60_000);
  if (nowTick !== tick) { tick = nowTick; reqThisMin = 0; }
  if (reqThisMin >= MAX_REQ_PER_MIN) return false;
  reqThisMin++;
  return true;
}

// ====== util: write buffer to tmp wav/webm for OpenAI ======
function tmpPath(ext: string) {
  const id = crypto.randomBytes(8).toString("hex");
  return path.join("/tmp", `carv2_${id}.${ext}`);
}

// ====== /stt ======
router.post("/stt",
  upload.single("audio"),
  async (req, res) => {
    try {
      if (!OPENAI_API_KEY) return res.status(500).json({ error: "OPENAI_API_KEY not set" });
      if (breakerOpen()) return res.status(429).json({ error: "ASR cooldown (circuit open). Try shortly." });
      if (!rateOK()) return res.status(429).json({ error: "Rate limited for this minute" });

      const { sessionSeconds = "0" } = req.body ?? {};
      if (Number(sessionSeconds) / 60 > MAX_MINUTES_PER_SESSION) {
        return res.status(402).json({ error: "Session budget exceeded" });
      }

      const buf = req.file?.buffer;
      const mime = req.file?.mimetype || "audio/webm";
      if (!buf) return res.status(400).json({ error: "no audio" });

      // save to disk; OpenAI SDK accepts streams/Blob too, but disk is simplest here
      const ext = mime.includes("wav") ? "wav" : (mime.includes("ogg") ? "ogg" : "webm");
      const p = tmpPath(ext);
      fs.writeFileSync(p, buf);

      // call OpenAI Whisper
      const form = new FormData();
      // @ts-ignore ‚Äì Node18 has global Blob/FormData
      form.append("file", new Blob([fs.readFileSync(p)]), `audio.${ext}`);
      form.append("model", "whisper-1");
      // optional: "language", "temperature"

      const r = await fetch("https://api.openai.com/v1/audio/transcriptions", {
        method: "POST",
        headers: { Authorization: `Bearer ${OPENAI_API_KEY}` },
        body: form as any
      });

      fs.unlink(p, () => {});

      if (!r.ok) {
        const txt = await r.text().catch(() => "");
        breakerTrip();
        return res.status(502).json({ error: "ASR failure", detail: txt });
      }

      const data = await r.json();
      breakerSuccess();
      return res.json({ text: data.text ?? "" });
    } catch (e: any) {
      breakerTrip();
      return res.status(500).json({ error: e.message });
    }
  }
);

export default router;


wire it (additive) in src/index.ts:

import carModeV2 from "./modules/carModeV2/index.js";
app.use("/car-v2", carModeV2);
console.log("[CARV2] POST /car-v2/stt");


install deps:

"dependencies": {
  "express": "^4.19.2",
  "multer": "^1.4.5-lts.1",
  "better-sqlite3": "^9.6.0",
  "zod": "^3.23.8"
}


(You already have most; add multer.)

2) client ‚Äî React ‚ÄúCar Mode (V2)‚Äù panel

Uses MediaRecorder to capture Opus in WebM chunks.

VAD: simple energy + zero-crossing check to start/stop recording; no voice ‚Üí no API calls ‚Üí no burn.

After each utterance, we POST to /car-v2/stt.

If transcript matches your calendar intent, we auto-call /calendar-multi/command.

src/ui/CarModeV2Panel.tsx

import React, { useEffect, useRef, useState } from "react";

type Props = {
  userId: string;
  tz?: string;
};

const MAX_SESSION_SEC = 60 * 5; // same as server default 5 min

export default function CarModeV2Panel({ userId, tz = "America/Los_Angeles" }: Props) {
  const [listening, setListening] = useState(false);
  const [log, setLog] = useState<string[]>([]);
  const [sessionSec, setSessionSec] = useState(0);

  const mediaRef = useRef<MediaStream | null>(null);
  const recRef = useRef<MediaRecorder | null>(null);
  const chunksRef = useRef<BlobPart[]>([]);
  const vadActiveRef = useRef(false);
  const vadSilenceMs = 800; // stop after 800ms of silence
  const vadTimerRef = useRef<number | null>(null);
  const meterRef = useRef<ScriptProcessorNode | null>(null);
  const audioCtxRef = useRef<AudioContext | null>(null);

  // simple regex for calendar intents
  const CALENDAR_VERBS = /(create|schedule|book|find).*(meeting|event|slot)/i;

  useEffect(() => {
    let t: any;
    if (listening) {
      t = setInterval(() => setSessionSec(s => s + 1), 1000);
    } else {
      setSessionSec(0);
    }
    return () => clearInterval(t);
  }, [listening]);

  async function start() {
    if (listening) return;
    try {
      const ms = await navigator.mediaDevices.getUserMedia({ audio: { echoCancellation: true, noiseSuppression: true }, video: false });
      mediaRef.current = ms;

      // recorder
      const rec = new MediaRecorder(ms, { mimeType: "audio/webm;codecs=opus", bitsPerSecond: 32_000 });
      recRef.current = rec;
      rec.ondataavailable = (e) => { if (e.data.size) chunksRef.current.push(e.data); };
      rec.onstop = async () => { await flushChunk(); };

      // VAD
      const ctx = new AudioContext();
      audioCtxRef.current = ctx;
      const src = ctx.createMediaStreamSource(ms);
      const proc = ctx.createScriptProcessor(2048, 1, 1);
      meterRef.current = proc;
      src.connect(proc);
      proc.connect(ctx.destination);

      proc.onaudioprocess = (ev) => {
        const data = ev.inputBuffer.getChannelData(0);
        let sum = 0; let zc = 0;
        for (let i = 0; i < data.length; i++) {
          sum += Math.abs(data[i]);
          if (i && (data[i] > 0) !== (data[i - 1] > 0)) zc++;
        }
        const energy = sum / data.length;
        // crude VAD thresholds
        const speaking = energy > 0.02 && zc > 20;

        if (speaking && !vadActiveRef.current) {
          // start recording
          vadActiveRef.current = true;
          chunksRef.current = [];
          rec.start();
          logLine("üéôÔ∏è voice detected ‚Äî recording‚Ä¶");
          if (vadTimerRef.current) { window.clearTimeout(vadTimerRef.current); vadTimerRef.current = null; }
        } else if (!speaking && vadActiveRef.current) {
          // schedule stop after silenceMs
          if (!vadTimerRef.current) {
            vadTimerRef.current = window.setTimeout(() => {
              vadActiveRef.current = false;
              try { rec.stop(); } catch {}
              logLine("üõë silence ‚Äî sending chunk");
              vadTimerRef.current = null;
            }, vadSilenceMs) as any;
          }
        }
      };

      setListening(true);
      logLine("Car Mode V2 listening‚Ä¶");
    } catch (e: any) {
      logLine("mic error: " + e.message);
    }
  }

  async function stop() {
    setListening(false);
    if (meterRef.current) { meterRef.current.disconnect(); meterRef.current = null; }
    if (audioCtxRef.current) { try { await audioCtxRef.current.close(); } catch {} audioCtxRef.current = null; }
    if (recRef.current && recRef.current.state !== "inactive") { try { recRef.current.stop(); } catch {} }
    if (mediaRef.current) { mediaRef.current.getTracks().forEach(t => t.stop()); mediaRef.current = null; }
    logLine("Car Mode V2 stopped.");
  }

  async function flushChunk() {
    const blob = new Blob(chunksRef.current, { type: "audio/webm" });
    chunksRef.current = [];
    if (blob.size < 2000) { return; } // too tiny
    if (!listening) return;

    // POST to STT
    const fd = new FormData();
    fd.append("audio", blob, "chunk.webm");
    fd.append("sessionSeconds", String(sessionSec));

    try {
      const r = await fetch("/car-v2/stt", { method: "POST", body: fd });
      const data = await r.json();
      if (!r.ok) { logLine("stt fail: " + (data.error || r.status)); return; }
      const text = (data.text || "").trim();
      if (!text) { logLine("‚Ä¶(silence)"); return; }

      logLine("you: " + text);

      // if it looks like a calendar command, auto route it
      if (CALENDAR_VERBS.test(text)) {
        const cmdRes = await fetch("/calendar-multi/command", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ userId, text, tz, workHours: { start: "09:00", end: "18:00" } })
        });
        const j = await cmdRes.json();
        if (cmdRes.ok && j.eventId) {
          speak(`Booked. Starts at ${new Date(j.start).toLocaleTimeString()}.`);
          logLine(`‚úÖ booked: ${j.htmlLink}`);
        } else if (cmdRes.ok && j.intent === "find_free") {
          speak("No time given. I‚Äôll look for a free slot.");
          logLine("suggestion: " + JSON.stringify(j.request));
        } else {
          logLine("command error: " + (j.error || "unknown"));
        }
      } else {
        // still speak back so you know it heard you
        speak(text);
      }
    } catch (e: any) {
      logLine("stt error: " + e.message);
    }
  }

  function speak(msg: string) {
    try {
      const u = new SpeechSynthesisUtterance(msg);
      window.speechSynthesis.speak(u);
    } catch {}
  }

  function logLine(s: string) { setLog(prev => [s, ...prev].slice(0, 100)); }

  return (
    <div className="p-4 space-y-3">
      <div className="flex items-center gap-3">
        <button
          className={`px-4 py-2 rounded ${listening ? "bg-red-600" : "bg-green-600"} text-white`}
          onClick={listening ? stop : start}
        >
          {listening ? "Stop (Car Mode V2)" : "Start (Car Mode V2)"}
        </button>
        <div className="text-sm opacity-70">session: {Math.floor(sessionSec/60)}m {sessionSec%60}s</div>
      </div>
      <div className="text-xs font-mono leading-5 max-h-48 overflow-auto border p-2 rounded bg-black text-green-300">
        {log.map((l,i)=><div key={i}>{l}</div>)}
      </div>
      <p className="text-xs opacity-70">
        Tip: say ‚Äúcreate a team meeting today at 12:30 with &quot;colleague calendar&quot; for 30 minutes‚Äù.
      </p>
    </div>
  );
}


Mount it in your sidebar as a NEW entry (‚ÄúCar Mode V2‚Äù), separate from any existing ‚ÄúCar Mode‚Äù thing that‚Äôs misbehaving.

3) why this fixes the pain

No endless stream ‚Üí we only send audio per utterance (VAD-gated). Zero chatter = no money burn.

Circuit breaker + rate limit ‚Üí if Whisper flakes or your key hiccups, we stop hammering and tell you.

Direct intent routing ‚Üí recognized text immediately calls your /calendar-multi/command; you don‚Äôt touch forms.

Reversible & isolated ‚Üí lives at /car-v2/* + a new panel. Your old pipelines keep humming.

4) quick checklist

Add the new files, wire /car-v2 route.

replit secrets set OPENAI_API_KEY=...

Add UI panel entry: Car Mode (V2) ‚Üí render CarModeV2Panel.

Teach aliases once (so ‚Äúcolleague calendar‚Äù resolves):
POST /calendar-multi/alias/upsert { alias, email, icsUrl }

Press Start (Car Mode V2) and say:

‚Äúcreate a team meeting today at 12:30 with ‚Äòcolleague calendar‚Äô for 30 minutes‚Äù